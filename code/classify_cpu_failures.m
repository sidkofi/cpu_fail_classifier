% CLASSIFY_CPU_FAILURES - Main script for CPU Failure Classification Project
%
% Description:
%   This script performs the following steps:
%   1. Loads simulated CPU benchmark data.
%   2. Defines parameters for preprocessing and feature extraction.
%   3. Iterates through each run in the dataset.
%   4. Preprocesses the frequency data (filtering).
%   5. Performs wavelet decomposition.
%   6. Extracts key features (Peak Count, Magnitude Ratio, Separated Distance, MAD).
%   7. Applies a rule-based classification logic using thresholds on the features.
%   8. Calculates and displays the overall accuracy and a confusion matrix.
%   9. Optionally generates visualizations for analysis (commented out by default).
%
% Requires:
%   - MATLAB Wavelet Toolbox
%   - benchmark_data.csv (generated by generate_cpu_benchmark_data.m)
%   - load_benchmark_data.m (helper function)
%
% Author: Sidney Taylor

clear; clc; close all; % Start with a clean environment

%% 1. Load Existing Data
fprintf('--- CPU Failure Classification Script ---\n');
try
    % Load data into table and cell array
    [data, run_data_cell_optional] = load_benchmark_data('../data/benchmark_data.csv');
    num_total_runs = max(data.Run_ID);
    fprintf('Loaded data for %d runs.\n', num_total_runs);
catch ME
    error('Failed to load benchmark data. Ensure benchmark_data.csv exists and load_benchmark_data.m is accessible. Error: %s', ME.message);
end

%% 2. Define Parameters

% --- Preprocessing Parameters ---
Fs = 10;            % Don't change this
ma_window = 3;      % Moving average window size
butter_order = 2;   % Butterworth filter order
butter_cutoff = 3.0;% Butterworth cutoff frequency (Hz)

% --- Wavelet Parameters ---
wavelet_name = 'db4'; % Wavelet family to use
num_levels = 6;     % Number of decomposition levels
detail_level = 1;   % Focus feature extraction on Detail Level 1

% --- Feature Extraction Parameters ---
% For Significant Peak Count (Feature 1)
peak_height_factor_sig = 1.5; % MinPeakHeight = factor * std(abs(D1))
peak_dist_sec_sig = 0.2;      % MinPeakDistance in seconds for counting peaks

% For Magnitude Ratio (Feature 2) - Window around peaks to exclude from 'rest' average
peak_exclude_window_samples = 5;

% For Separated Peak Distance (Feature 3)
min_dist_for_feature_sec = 3.0; % Min separation required (seconds)
min_peak_height_factor_for_dist = 1.5; % Factor for finding candidate peaks for distance

% --- Classification Thresholds (feel free to play around with these to try and get a higher accuracy) ---
threshold_mad_max_for_none = 0.0006;
threshold_pk_count_min_for_none = 40; % Condition used alongside MAD for 'None'
threshold_freq_osc_min_peak_count = 6;
threshold_freq_osc_max_ratio = 20.0;
threshold_mad_min_for_freq_osc = 0.00065; % Lower bound MAD for Freq Osc
threshold_thermal_min_ratio_final = 39;
threshold_mad_min_for_thermal = 0.002; % Lower bound MAD for Thermal

fprintf('Parameters set. Fs=%.1f, MA_Win=%d, Butterworth=(%d, %.1fHz), Wavelet=%s(%d)\n', ...
        Fs, ma_window, butter_order, butter_cutoff, wavelet_name, num_levels);
fprintf('Classification Thresholds: MAD_None<%.4f, PkCnt_None>%d, PkCnt_Osc>%d, Ratio_Osc<%.1f, MAD_Osc>%.5f, Ratio_Therm>%.0f, MAD_Therm>%.3f\n', ...
        threshold_mad_max_for_none, threshold_pk_count_min_for_none, threshold_freq_osc_min_peak_count, ...
        threshold_freq_osc_max_ratio, threshold_mad_min_for_freq_osc, threshold_thermal_min_ratio_final, threshold_mad_min_for_thermal);

%% 3. Extract Features and Classify for Each Run

% Initialize storage
% Features: [PeakCount, MagRatio, PeakDistSeparated, MeanAbsDev]
num_features = 4;
new_features = NaN(num_total_runs, num_features); % Use NaN for runs with errors
true_failure_types = cell(num_total_runs, 1);
predicted_failure_types = cell(num_total_runs, 1);

fprintf('Processing %d runs...\n', num_total_runs);
tic; % Start timer

for i = 1:num_total_runs % Loop through each Run ID
    run_id = i;
    run_indices = data.Run_ID == run_id;
    run_subset = data(run_indices, :);

    if isempty(run_subset)
        warning('Run ID %d has no data in the table. Skipping.', run_id);
        true_failure_types{i} = 'Invalid_Data';
        predicted_failure_types{i} = 'Invalid_Data';
        continue;
    end

    % Get true label
    true_failure_types{i} = char(run_subset.Failure_Type(1));

    % Extract time and frequency data for this run
    time_data = run_subset.Time;
    raw_freq_data = run_subset.Frequency_GHz;
    n_samples = length(time_data);

    % Basic data validity check
    if isempty(time_data) || isempty(raw_freq_data) || length(time_data) ~= length(raw_freq_data) || all(isnan(raw_freq_data)) || n_samples < ma_window || n_samples < butter_order*3
         warning('Invalid or insufficient data for Run ID %d (%s). Skipping feature extraction.', run_id, true_failure_types{i});
         true_failure_types{i} = 'Invalid_Data'; % Mark as invalid if data is bad
         predicted_failure_types{i} = 'Invalid_Data';
         continue;
    end

    % --- Preprocessing ---
    freq_ma = movmean(raw_freq_data, ma_window, 'omitnan');
    [b_filt, a_filt] = butter(butter_order, butter_cutoff/(Fs/2));
    freq_data = filtfilt(b_filt, a_filt, freq_ma); % Filtered data

    % --- Wavelet Decomposition & D1 Reconstruction ---
    try
        [c, l] = wavedec(freq_data, num_levels, wavelet_name);
        detail_recon = wrcoef('d', c, l, wavelet_name, detail_level); % D1
        abs_detail_recon = abs(detail_recon);
    catch ME_wavelet
        warning('Wavelet analysis failed for Run ID %d (%s). Error: %s Skipping.', run_id, true_failure_types{i}, ME_wavelet.message);
        true_failure_types{i} = 'Invalid_Data';
        predicted_failure_types{i} = 'Invalid_Data';
        continue;
    end

    % --- Feature Calculation ---
    try
        % Feature 1: Significant Peak Count
        min_peak_h_sig = peak_height_factor_sig * std(abs_detail_recon);
        min_peak_d_samples_sig = round(peak_dist_sec_sig * Fs);
        if min_peak_d_samples_sig < 1, min_peak_d_samples_sig = 1; end
        [pks_sig, ~] = findpeaks(abs_detail_recon, 'MinPeakHeight', min_peak_h_sig, 'MinPeakDistance', min_peak_d_samples_sig);
        pk_count = length(pks_sig);

        % Feature 2: Top 2 Peak Magnitude Ratio (Global Peaks)
        [pks_top_global, locs_top_global] = findpeaks(abs_detail_recon, 'SortStr', 'descend', 'NPeaks', 2);
        mag_ratio = 0; % Default
        if ~isempty(pks_top_global)
            mask = true(n_samples, 1);
            for p = 1:length(pks_top_global)
                 current_loc = locs_top_global(p);
                 if current_loc > 0 && current_loc <= n_samples
                    win_start = max(1, current_loc - peak_exclude_window_samples);
                    win_end = min(n_samples, current_loc + peak_exclude_window_samples);
                    mask(win_start:win_end) = false;
                 end
            end
            if any(mask)
                avg_rest_mag = mean(abs_detail_recon(mask));
                if avg_rest_mag > 1e-9
                     mag_ratio = mean(pks_top_global) / avg_rest_mag;
                else
                     mag_ratio = mean(pks_top_global) / (1e-9);
                end
            else
                mag_ratio = Inf; % Indicate invalid if mask removed all
            end
        end

        % Feature 3: Top 2 Peak Distance *with Minimum Separation*
        pk_dist_sep = 0; % Default
        min_peak_h_dist = min_peak_height_factor_for_dist * std(abs_detail_recon);
        min_dist_samples = round(min_dist_for_feature_sec * Fs);
        if min_dist_samples < 1, min_dist_samples = 1; end
        [pks_all_dist, locs_all_dist] = findpeaks(abs_detail_recon, 'MinPeakHeight', min_peak_h_dist, 'SortStr', 'descend');
        if length(pks_all_dist) >= 2
            first_peak_loc = locs_all_dist(1);
            for j = 2:length(pks_all_dist)
                second_peak_loc_candidate = locs_all_dist(j);
                if abs(second_peak_loc_candidate - first_peak_loc) >= min_dist_samples
                    pk_dist_sep = abs(second_peak_loc_candidate - first_peak_loc) / Fs;
                    break;
                end
            end
        end

        % Feature 4: Mean Absolute Deviation (MAD)
        mad_val = 0; % Default
        if n_samples > 0 && ~all(isnan(abs_detail_recon))
            mean_abs_d1 = mean(abs_detail_recon);
            mad_val = mean(abs(abs_detail_recon - mean_abs_d1));
        end

        % Store Features
        new_features(i, :) = [pk_count, mag_ratio, pk_dist_sep, mad_val];

    catch ME_feature
        warning('Feature extraction failed for Run ID %d (%s). Error: %s Skipping.', run_id, true_failure_types{i}, ME_feature.message);
        true_failure_types{i} = 'Invalid_Data';
        predicted_failure_types{i} = 'Invalid_Data';
        continue; % Skip classification if features failed
    end

    % --- Classification Logic ---
    % Apply rules based on extracted features
    if mad_val < threshold_mad_max_for_none && pk_count > threshold_pk_count_min_for_none
        predicted_failure_types{i} = 'None';
    elseif pk_count > threshold_freq_osc_min_peak_count && mag_ratio < threshold_freq_osc_max_ratio && mad_val > threshold_mad_min_for_freq_osc
        predicted_failure_types{i} = 'Frequency_Oscillation';
    elseif mag_ratio > threshold_thermal_min_ratio_final && mad_val > threshold_mad_min_for_thermal
        predicted_failure_types{i} = 'Thermal_Throttling';
    else
        predicted_failure_types{i} = 'Stuck_Frequency';
    end

end % End of loop through runs
toc; % Stop timer
fprintf('Feature extraction and classification complete.\n');

%% 4. Calculate and Display Accuracy

fprintf('\n--- Evaluating Classification Results ---\n');

% Remove any runs marked as 'Invalid_Data' during processing
valid_indices = ~strcmp(true_failure_types, 'Invalid_Data');
true_labels_valid = true_failure_types(valid_indices);
predicted_labels_valid = predicted_failure_types(valid_indices);
num_valid_runs = length(true_labels_valid);

if num_valid_runs == 0
    error('No valid runs found after processing. Cannot calculate accuracy.');
end
fprintf('Evaluating on %d valid runs.\n', num_valid_runs);

% Overall Accuracy
correct_predictions = strcmp(true_labels_valid, predicted_labels_valid);
overall_accuracy = sum(correct_predictions) / num_valid_runs;

fprintf('Overall Accuracy: %.2f%%\n', overall_accuracy * 100);

% Confusion Matrix
% Define the expected order of labels for consistency
class_order = {'None', 'Frequency_Oscillation', 'Stuck_Frequency', 'Thermal_Throttling'};
true_cat = categorical(true_labels_valid, class_order);
pred_cat = categorical(predicted_labels_valid, class_order);

figure('Name', 'Confusion Matrix');
cm = confusionchart(true_cat, pred_cat);
cm.Title = sprintf('CPU Failure Classification (Overall Acc: %.2f%%)', overall_accuracy * 100);


fprintf('\n--- Classification Report Complete ---\n');